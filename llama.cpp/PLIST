@comment $NetBSD$
bin/convert_hf_to_gguf.py
bin/llama-baby-llama
bin/llama-batched
bin/llama-batched-bench
bin/llama-bench
bin/llama-cli
bin/llama-convert-llama2c-to-ggml
bin/llama-cvector-generator
bin/llama-embedding
bin/llama-eval-callback
bin/llama-export-lora
bin/llama-gbnf-validator
bin/llama-gguf
bin/llama-gguf-hash
bin/llama-gguf-split
bin/llama-gritlm
bin/llama-imatrix
bin/llama-infill
bin/llama-llava-cli
bin/llama-lookahead
bin/llama-lookup
bin/llama-lookup-create
bin/llama-lookup-merge
bin/llama-lookup-stats
bin/llama-minicpmv-cli
bin/llama-parallel
bin/llama-passkey
bin/llama-perplexity
bin/llama-quantize
bin/llama-quantize-stats
bin/llama-retrieval
bin/llama-save-load-state
bin/llama-server
bin/llama-simple
bin/llama-speculative
bin/llama-tokenize
include/ggml-alloc.h
include/ggml-backend.h
include/ggml-blas.h
include/ggml-cann.h
include/ggml-cuda.h
include/ggml-kompute.h
include/ggml-metal.h
include/ggml-rpc.h
include/ggml-sycl.h
include/ggml-vulkan.h
include/ggml.h
include/llama.h
lib/cmake/llama/llama-config.cmake
lib/cmake/llama/llama-version.cmake
lib/libggml.so
lib/libllama.so
lib/libllava_shared.so
lib/pkgconfig/llama.pc
