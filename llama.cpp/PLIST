@comment $NetBSD$
bin/baby-llama
bin/batched
bin/batched-bench
bin/benchmark
bin/convert-hf-to-gguf.py
bin/convert-llama2c-to-ggml
bin/embedding
bin/eval-callback
bin/export-lora
bin/finetune
bin/gguf
bin/gguf-split
bin/gritlm
bin/imatrix
bin/infill
bin/llama-bench
bin/llava-cli
bin/lookahead
bin/lookup
bin/lookup-create
bin/lookup-merge
bin/lookup-stats
bin/main
bin/parallel
bin/passkey
bin/perplexity
bin/quantize
bin/quantize-stats
bin/retrieval
bin/save-load-state
bin/server
bin/simple
bin/speculative
bin/test-autorelease
bin/test-backend-ops
bin/test-chat-template
bin/test-grad0
bin/test-grammar-integration
bin/test-grammar-parser
bin/test-json-schema-to-grammar
bin/test-llama-grammar
bin/test-model-load-cancel
bin/test-quantize-fns
bin/test-quantize-perf
bin/test-rope
bin/test-sampling
bin/test-tokenizer-0
bin/test-tokenizer-1-bpe
bin/test-tokenizer-1-spm
bin/tokenize
bin/train-text-from-scratch
include/ggml-alloc.h
include/ggml-backend.h
include/ggml.h
include/llama.h
lib/cmake/Llama/LlamaConfig.cmake
lib/cmake/Llama/LlamaConfigVersion.cmake
lib/libllama.a
lib/pkgconfig/llama.pc
