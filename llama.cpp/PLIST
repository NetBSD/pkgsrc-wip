@comment $NetBSD$
bin/convert-hf-to-gguf.py
bin/llama-baby-llama
bin/llama-batched
bin/llama-batched-bench
bin/llama-bench
bin/llama-bench-matmult
bin/llama-cli
bin/llama-convert-llama2c-to-ggml
bin/llama-cvector-generator
bin/llama-embedding
bin/llama-eval-callback
bin/llama-export-lora
bin/llama-finetune
bin/llama-gbnf-validator
bin/llama-gguf
bin/llama-gguf-split
bin/llama-gritlm
bin/llama-imatrix
bin/llama-infill
bin/llama-llava-cli
bin/llama-lookahead
bin/llama-lookup
bin/llama-lookup-create
bin/llama-lookup-merge
bin/llama-lookup-stats
bin/llama-parallel
bin/llama-passkey
bin/llama-perplexity
bin/llama-quantize
bin/llama-quantize-stats
bin/llama-retrieval
bin/llama-save-load-state
bin/llama-server
bin/llama-simple
bin/llama-speculative
bin/llama-tokenize
bin/llama-train-text-from-scratch
include/ggml-alloc.h
include/ggml-backend.h
include/ggml.h
include/llama.h
lib/cmake/Llama/LlamaConfig.cmake
lib/cmake/Llama/LlamaConfigVersion.cmake
lib/libllama.a
lib/pkgconfig/llama.pc
